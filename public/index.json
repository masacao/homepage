[{"authors":null,"categories":null,"content":"Zheng Cao (ÊõπÊîø) is a Ph.D. candidate, majoring in computer science, Zhejiang University, under the supervision from Prof. Jian Wu. He is member of ZJU RealDoctor AI Research Centre and ZJU Innovative Drug Discovery Insitute. His research interests include AI for medical image analysis, AI for drug discovery and Blockchain Technology. He serves as a CTO / Co-founder for a web3 startup TraFinity ltd. as well. Here is my full publications list. Download my resume.\n","date":1681084800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1681084800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Zheng Cao (ÊõπÊîø) is a Ph.D. candidate, majoring in computer science, Zhejiang University, under the supervision from Prof. Jian Wu. He is member of ZJU RealDoctor AI","tags":null,"title":"Zheng Cao","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"www.caoz.top/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"www.caoz.top/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Zheng Cao"],"categories":["deep learning","Web3"],"content":"Introduction Welcome to my latest blog post, where I will be introducing a basic benchmark for PyTorch, the popular deep learning library. As a machine learning enthusiast, I understand the importance of measuring the performance of different hardware setups for deep learning tasks. By comparing the capabilities of various CPUs and GPUs, we can better understand the trade-offs and make more informed decisions when building our machine learning infrastructure.\nIn this post, I will present the results of a basic PyTorch benchmark that I ran on various CPUs and GPUs. I will discuss the performance of these hardware components in terms of iterations per second (it/s), and provide some insights into the differences observed.\nCode from tqdm import tqdm import torch import os,sys # os.environ['CUDA_VISIBLE_DEVICES']='4' # device=torch.device(\u0026quot;cuda:4\u0026quot; if torch.cuda.is_available() else \u0026quot;cpu\u0026quot;) # print(device) @torch.jit.script def foo(): x = torch.ones((1024 * 12, 1024 * 12), dtype=torch.float32) y = torch.ones((1024 * 12, 1024 * 12), dtype=torch.float32) x = x.cuda() y = y.cuda() z = x + y return z if __name__ == '__main__': z0 = None for _ in tqdm(range(10000000000)): zz = foo() if z0 is None: z0 = zz else: z0 += zz Results The following are the results obtained from the benchmarking experiment:\n(Updated 20/Apr)\nHardware Component Performance (it/s) Nvidia 3090 GPU 670 AMD Ryzen 9 3900X CPU 21 Apple M1 CPU 48 Server CPU 74 Server GPU GTX1080Ti 300 Server GPU (Overheat) 55 Tencent Cloud 75 IIAIM Node GPU01 RTX3080 402 Tencent VENUS V100 GPU 677 AMD Ryzen 5 5600G CPU 25 Nvidia RTX3060 GPU 320 Analysis From the results, we can observe that GPUs generally outperform CPUs in terms of performance when running PyTorch tasks. For instance, the Nvidia 3090 GPU achieved 670 it/s, which is 6.8% of its performance when running on a CPU. This is a remarkable improvement, and demonstrates the power of GPUs for deep learning tasks.\nWhen comparing different CPUs, we can see that the Apple M1 and Server CPU show better performance than the AMD Ryzen 9 3900X and Ryzen 5 5600G. However, the difference in performance between these CPUs is not as significant as the difference between GPUs.\nOn the GPU side, the Nvidia RTX3090 and Tencent VENUS V100 show the highest performance, followed by the IIAIM Node GPU01 RTX3080 and Nvidia RTX3060. Interestingly, the Server GPU GTX1080Ti and the overheat variant show comparatively lower performance, suggesting that thermal management plays a crucial role in GPU performance.\nConclusion In conclusion, this basic PyTorch benchmark highlights the advantages of using GPUs for deep learning tasks over CPUs. The performance gap between GPUs and CPUs is significant, and it is essential to choose the right hardware for your specific machine learning projects. It is also important to consider factors such as thermal management when selecting a GPU to ensure optimal performance.\nAs a final note, we hope to see further support for GPUs and neural engines in the near future, which could potentially unlock even greater performance gains for deep learning tasks.\n","date":1681084800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681084800,"objectID":"c1be24d480ab797ff1693e1c47ff72b7","permalink":"www.caoz.top/post/a-simple-pytorch-implementation-benchmark/","publishdate":"2023-04-10T00:00:00Z","relpermalink":"www.caoz.top/post/a-simple-pytorch-implementation-benchmark/","section":"post","summary":"Introduction Welcome to my latest blog post, where I will be introducing a basic benchmark for PyTorch, the popular deep learning library. As a machine learning enthusiast, I understand the importance of measuring the performance of different hardware setups for deep learning tasks.","tags":["deep learning","Web3"],"title":"A Simple PyTorch Implementation Benchmark","type":"post"},{"authors":["Zheng Cao","Liming Xu","Danny Z. Chen","Honghao Gao","Jian Wu"],"categories":null,"content":" ","date":1679702400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679702400,"objectID":"302b22cc8d3892e3ca2199abd72fac15","permalink":"www.caoz.top/publication/a-robust-shape-aware-rib-fracture-detection-and-segmentation-framework-with-contrastive-learning/","publishdate":"2023-03-25T00:00:00Z","relpermalink":"www.caoz.top/publication/a-robust-shape-aware-rib-fracture-detection-and-segmentation-framework-with-contrastive-learning/","section":"publication","summary":"Deep learning model for rib fracture diagnose (detection and segmentation.","tags":["medical imaging"],"title":"A Robust Shape-Aware Rib Fracture Detection and Segmentation Framework with Contrastive Learning","type":"publication"},{"authors":null,"categories":null,"content":"üè† Introduction https://t.xyz\nWe are a web3 traffic and community centric company that created Let\u0026rsquo;s meme \u0026ndash; a community management and traffic-fi protocol tool designed to help thousands of future businesses, communities and brands better market their blockchain-based technology and their web3 vision.\nWhat is LetsMeMe? LetsMeMe is the world\u0026rsquo;s first trafficFi based community management platform. It is a social layer-2 network built upon traditional social media, i.e Twitter. LetsMeMe integrates web3 functionality with web2 social media platforms like Twitter and Youtube, to benefit and enhance crypto-native communities. Its existence will enable the creation of the largest web3 traffic network driven entirely by communities.\nVision Empower businesses of all sizes to reach beyond their target audience and achieve their marketing goals. Create the farthest-reaching web3 traffic network Mission Allow all communities to manage and engage their members more easily. Destabilize the web2 traffic monopoly, allowing all organizations to advance their vision. Values Use advancing technology to drive marketing Holders themselves are a community‚Äôs builders ","date":1664582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664582400,"objectID":"b86f01f7714019c7731c1892a7bc2591","permalink":"www.caoz.top/project/lets-meme/","publishdate":"2022-10-01T00:00:00Z","relpermalink":"www.caoz.top/project/lets-meme/","section":"project","summary":"A Web3 TrafficFi Protocol","tags":["Web3"],"title":"Lets MeMe","type":"project"},{"authors":null,"categories":null,"content":"Protect Your NFTs with TokenPatronus Are you worried about the security of your non-fungible tokens (NFTs)? Look no further than TokenPatronus, the decentralized NFT anti-theft mechanism that provides strong property protection for NFT holders.\nWhat is TokenPatronus? TokenPatronus is a decentralized anti-theft mechanism designed specifically for NFTs. It contains pre-event protection, in-event interruption, and post-event replevin enhancements for the complete NFT transaction process. Four modules make up the TokenPatronus anti-theft mechanism:\nDecentralized access control (DAC) Decentralized risk management (DRM) Decentralized arbitration system (DAS) ERC-721G standard smart contract These modules work together to ensure the trust and robustness of the TokenPatronus mechanism.\nHow does TokenPatronus work? TokenPatronus divides the transaction of an NFT into three stages: pre-event protection, in-event interruption, and post-event process. Each stage has a corresponding role for TokenPatronus to play.\nDuring pre-event protection, TokenPatronus uses its decentralized identification module to verify the identity of both parties involved in the transaction. This helps prevent fraudulent transactions from occurring in the first place.\nIn the event that a fraudulent transaction does occur, TokenPatronus can interrupt it using its decentralized risk management engine. This engine combines information from various sources, including deep learning models trained on transaction history stored in decentralized storage. The engine assesses the risk status of each transaction and can halt any suspicious activity.\nFinally, if an NFT is stolen or lost after a successful transaction has taken place, TokenPatronus provides post-event replevin enhancements to help recover it. This includes the use of a decentralized arbitration system to resolve disputes and the ERC-721G smart contract standard to ensure that ownership of the NFT is properly recorded.\nWhy choose TokenPatronus? TokenPatronus provides several benefits over other anti-theft mechanisms on the market. First and foremost, it is decentralized, meaning that there is no central authority controlling the system. This makes it more resistant to attacks and less vulnerable to corruption.\nAdditionally, TokenPatronus is designed specifically for NFTs, meaning that it provides tailored protection for this unique asset class. It supports the general ERC-721 standard and will support more blockchains in the future, making it a versatile solution for NFT holders.\nFinally, TokenPatronus is easy to use. It includes a front-end web interface that allows users to easily manage their NFTs and perform operations such as adding and unlocking them.\nConclusion If you\u0026rsquo;re an NFT holder looking for strong property protection, look no further than TokenPatronus. Its decentralized anti-theft mechanism provides pre-event protection, in-event interruption, and post-event replevin enhancements to ensure the security of your NFTs. With its tailored support for ERC-721 standard NFTs and easy-to-use web interface, TokenPatronus is the perfect solution for anyone looking to protect their valuable digital assets.\n","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656633600,"objectID":"dd07458b540516e75cc7e16ba5571372","permalink":"www.caoz.top/project/erc-721g/","publishdate":"2022-07-01T00:00:00Z","relpermalink":"www.caoz.top/project/erc-721g/","section":"project","summary":"A Ethernum NFT anti-theft Standard","tags":["Web3"],"title":"ERC-721G","type":"project"},{"authors":["Haihua Zhu","Haojie Yu","Fan Zhang","Zheng Cao","Fuli Wu","Fudong Zhu"],"categories":null,"content":" ","date":1647820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647820800,"objectID":"b483c5f9dbe3196cdbe3278b50069bc3","permalink":"www.caoz.top/publication/automatic-segmentation-and-detection-of-ectopic-eruption-of-the-first-permanent-molars-on-panoramic-radiographs-based-on-nnu-net/","publishdate":"2022-03-21T00:00:00Z","relpermalink":"www.caoz.top/publication/automatic-segmentation-and-detection-of-ectopic-eruption-of-the-first-permanent-molars-on-panoramic-radiographs-based-on-nnu-net/","section":"publication","summary":"Periodontal Bone Loss assessment.","tags":["medical imaging"],"title":"Automatic Segmentation and Detection of Ectopic Eruption of the First Permanent Molars on Panoramic Radiographs Based on nnU‚ÄêNet","type":"publication"},{"authors":["Zheng Cao","Xiang Pan","Hongyun Yu","Shiyuan Hua","Da Wang","Danny Z. Chen","Min Zhou","Jian Wu"],"categories":null,"content":" ","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"17810488f50771be6d396c56a2c82094","permalink":"www.caoz.top/publication/a-deep-learning-approach-for-detecting-colorectal-cancer-via-raman-spectra/","publishdate":"2022-05-02T00:00:00Z","relpermalink":"www.caoz.top/publication/a-deep-learning-approach-for-detecting-colorectal-cancer-via-raman-spectra/","section":"publication","summary":"Colorectal Cancer Diagnosis via Raman Spectra.","tags":["medical imaging"],"title":"A Deep Learning Approach for Detecting Colorectal Cancer via Raman Spectra","type":"publication"},{"authors":["Haihua Zhu","Zheng Cao","Luya Lian","Guanchen Ye","Honghao Gao","Jian Wu"],"categories":null,"content":" ","date":1641059940,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641059940,"objectID":"3a6c79a118a5e4a541f1467d28ad3247","permalink":"www.caoz.top/publication/cariesnet-a-deep-learning-approach-for-segmentation-of-multi-stage-caries-lesion-from-oral-panoramic-x-ray-image/","publishdate":"2022-01-03T20:00:00Z","relpermalink":"www.caoz.top/publication/cariesnet-a-deep-learning-approach-for-segmentation-of-multi-stage-caries-lesion-from-oral-panoramic-x-ray-image/","section":"publication","summary":"X-ray Segmentation of dental caries.","tags":["medical imaging"],"title":"CariesNet: A Deep learning Approach for Segmentation of multi-stage Caries lesion from Oral Panoramic X-Ray Image","type":"publication"},{"authors":["Linhong Jiang","Daqian Chen","Zheng Cao","Haihua Zhu","Fudong Zhu"],"categories":null,"content":" ","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"c8ce6f3c400a98b8b0d0399888845c5f","permalink":"www.caoz.top/publication/a-two-stage-deep-learning-architecture-for-radiographic-assessment-of-periodontal-bone-loss/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"www.caoz.top/publication/a-two-stage-deep-learning-architecture-for-radiographic-assessment-of-periodontal-bone-loss/","section":"publication","summary":"Periodontal Bone Loss assessment.","tags":["medical imaging"],"title":"A Two-Stage Deep Learning Architecture for Radiographic Assessment of Periodontal Bone Loss","type":"publication"},{"authors":["Zheng Cao","Cailin Mu","Haochao Ying","Jian Wu"],"categories":null,"content":" ","date":1626307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626307200,"objectID":"e014bc89f3d01c114a3dbe9f876fca3e","permalink":"www.caoz.top/publication/full-scale-attention-for-automated-covid-19-diagnosis-from-ct-images/","publishdate":"2021-07-15T00:00:00Z","relpermalink":"www.caoz.top/publication/full-scale-attention-for-automated-covid-19-diagnosis-from-ct-images/","section":"publication","summary":"Novel Attention-based Deep learning architecture for COVID-19 diagnose and lesion segmentation.","tags":["medical imaging"],"title":"Full Scale Attention for Automated COVID-19 Diagnosis from CT Images","type":"publication"},{"authors":null,"categories":null,"content":"Docking, Retrosynthesis, etc.\n","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"50db70ce71287f5d710b6dc18f77c391","permalink":"www.caoz.top/project/drug-discovery/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"www.caoz.top/project/drug-discovery/","section":"project","summary":"Project like Retrosynthesis, Docking, Affinity Prediction.","tags":["Deep Learning","Drug Discovery"],"title":"Drug Discovery","type":"project"},{"authors":null,"categories":null,"content":"MedIA is a wide subject, including different image modalities, i.e. CT/MRI/X-ray.\n","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"a40cce3bc3f23eac7c025f6580d44fa7","permalink":"www.caoz.top/project/medical-image-analysis/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"www.caoz.top/project/medical-image-analysis/","section":"project","summary":"Detection/Classification/Segmentation of the target organs.","tags":["Deep Learning"],"title":"Medical Image Analysis","type":"project"},{"authors":["Zheng Cao"],"categories":["deep learning"],"content":"Introduction nnUNet (no-new-network-Unet) is proposed to offer a end-to-end training for image segmentation, and achieve state-of-the-art performance in over 10 medical image segmentation tasks, as introduced in paper Automated Design of Deep Learning Methods for Biomedical Image Segmentation.\nAlthough uuUNet is easy to ulitize in 3D segmentation tasks, it\u0026rsquo;s difficult to train a personal dataset with 2d images. The preparation of dataset should follow strict guidelines.\nMethods Step1. Prepare Envs Create vitual environment in conda:\nconda create -n nnunet python=3.8 Prepare datafloders.\nDATASET/nnUNet_raw_data/Task002_Heart ‚îú‚îÄ‚îÄ nnUNet_preprocessed ‚îú‚îÄ‚îÄ nnUNet_trained_models ‚îú‚îÄ‚îÄ nnUNet_raw ‚îÇ ‚îú‚îÄ‚îÄ nnUNet_croped_data ‚îÇ ‚îú‚îÄ‚îÄ nnUNet_raw_data Step2. Covert Data Following guidance here.\nHow to use 2D data with nnU-Net nnU-Net was originally built for 3D images. It is also strongestwhen applied to 3D segmentation problems because a large proportion of itsdesign choices were built with 3D in mind. Also note that many 2D segmentationproblems, especially in the non-biomedical domain, may benefit from pretrainednetwork architectures which nnU-Net does not support. Still, there is certainlya need for an out of the box segmentation solution for 2D segmentationproblems. And also on 2D segmentation tasks nnU-Net cam perform extremely well!We have, for example, won a 2D task in the cell tracking challenge with nnU-Net(see our Nature Methods paper) and we have also successfully applied nnU-Net tohistopathological segmentation problems. Working with 2D data in nnU-Netrequires a small workaround in the creation of the dataset. Essentially, allimages must be converted to pseudo 3D images (so an image with shape (X, Y)needs to be converted to an image with shape (1, X, Y). The resulting imagemust be saved in nifti format. Hereby it is important to set the spacing of thefirst axis (the one with shape 1) to a value larger than the others. If you areworking with niftis anyways, then doing this should be easy for you. Thisexample here is intended for demonstrating how nnU-Net can be used with‚Äôregular‚Äô 2D images. We selected the massachusetts road segmentation datasetfor this because it can be obtained easily, it comes with a good amount oftraining cases but is still not too large to be difficult to handle.\nHere is my converting code:\nimport numpy as np from batchgenerators.utilities.file_and_folder_operations import * from nnunet.dataset_conversion.utils import generate_dataset_json from nnunet.paths import nnUNet_raw_data, preprocessing_output_dir from nnunet.utilities.file_conversions import convert_2d_image_to_nifti imgs = '/data/caozheng/*' masks = '/data/caozheng/*' root = 'DATASET/imagesTr' label_root = 'DATASET/labelsTr' for i in os.listdir(imgs): img = os.path.join(imgs, i) convert_2d_image_to_nifti(img, os.path.join(root, i.split('.')[0]), is_seg=False) print('FinishÔºö'+ i ) for i in os.listdir(masks): mask = os.path.join(masks, i) convert_2d_image_to_nifti(mask, os.path.join(label_root, i.split('.')[0]), is_seg=True, transform=lambda x: (x \u0026gt; 0).astype(int)) # transform=lambda x: (x \u0026gt; 0).astype(int) depends on label mode. print('FinishÔºö'+ i ) Then generate dataset.json file, which can be mantually created or created by default code.\ngenerate_dataset_json(os.path.join(raw, 'dataset.json'), os.path.join(raw, 'imagesTr'), os.path.join(raw, 'imagesTs'), ('background', 'caries'), {'background':0, 'caries':1}, 'caries_dataset', dataset_description='Private Test!', dataset_release='0.0.1') Step3. Move Data to suitable position The data format of nnUnet is fixed. Task002_Heart is composed of Task ID data name, imagesTr is training data, imagesTs is test data, labelsTr is the label of training data, data sample la_003_0000.nii.gz is marked by case sample name modal.nii. It is composed of gz. Different modals are distinguished by 0000/0001/0002/0003. I set the new task ID to 100.\nDATASET/nnUNet_raw/nnUNet_raw_data/Task002_Heart ‚îú‚îÄ‚îÄ dataset.json ‚îú‚îÄ‚îÄ imagesTr ‚îÇ ‚îú‚îÄ‚îÄ la_003_0000.nii.gz ‚îÇ ‚îú‚îÄ‚îÄ la_004_0000.nii.gz ‚îÇ ‚îú‚îÄ‚îÄ ... ‚îú‚îÄ‚îÄ imagesTs ‚îÇ ‚îú‚îÄ‚îÄ la_001_0000.nii.gz ‚îÇ ‚îú‚îÄ‚îÄ la_002_0000.nii.gz ‚îÇ ‚îú‚îÄ‚îÄ ... ‚îî‚îÄ‚îÄ labelsTr ‚îú‚îÄ‚îÄ la_003.nii.gz ‚îú‚îÄ‚îÄ la_004.nii.gz ‚îú‚îÄ‚îÄ ... Our original 2-dimensional data is RGB three-channel, we can regard the RGB three-channel data as three modalities, extract the data of different channels separately, convert the shape to (1, width, height), and save it as 3 with SimpleITK Dimensional data.\nStep4. Install Packages Download nnunet code:\nconda activate nnunet git clone https://github.com/MIC-DKFZ/nnUNet.git and install it.\npip install -e . Then set a environment variable\nexport nnUNet_raw_data_base=\u0026quot;/data/Project/nnUnet/Data/nnUNet_raw\u0026quot; export nnUNet_preprocessed=\u0026quot;/data/Project/nnUnet/Data/nnUNet_preprocessed\u0026quot; export RESULTS_FOLDER=\u0026quot;/data/Project/nnUnet/Data/nnUNet_trained_models\u0026quot; Step5. Pre-process and Training Pre-process will create large amount of data.\nnnUNet_plan_and_preprocess -t 2 Here 2 is the task id, which is identified in folder DATASET/nnUNet_raw/nnUNet_raw_data/Task002_Heart\nNow it\u0026rsquo;s prepared for training! Here we use 5-fold traning, \u0026ndash;npz means create softmax prediction.\nCUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 0 --npz CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 1 --npz CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 2 --npz CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 3 --npz CUDA_VISIBLE_DEVICES=6 nnUNet_train 2d nnUNetTrainerV2 Task002_Heart 4 --npz ","date":1618012800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618012800,"objectID":"012fc3b26f56f9218f6d6e7acbced9e2","permalink":"www.caoz.top/post/training-2d-nnunet-with-personal-dataset/","publishdate":"2021-04-10T00:00:00Z","relpermalink":"www.caoz.top/post/training-2d-nnunet-with-personal-dataset/","section":"post","summary":"Introduction nnUNet (no-new-network-Unet) is proposed to offer a end-to-end training for image segmentation, and achieve state-of-the-art performance in over 10 medical image segmentation tasks, as introduced in paper Automated Design of Deep Learning Methods for Biomedical Image Segmentation.","tags":["deep learning","image segmentation"],"title":"Training 2D nnUNet with personal dataset","type":"post"},{"authors":["Zheng Cao","Chuanbin Sun","Wenzhe Wang","Xiangshang Zheng","Jian Wu","Honghao Gao"],"categories":null,"content":" ","date":1591315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591315200,"objectID":"f71b509a49bae9030a2f7cae1df51e04","permalink":"www.caoz.top/publication/multi-modality-fusion-learning-for-the-automatic-diagnosis-of-optic-neuropathy/","publishdate":"2020-12-30T00:00:00Z","relpermalink":"www.caoz.top/publication/multi-modality-fusion-learning-for-the-automatic-diagnosis-of-optic-neuropathy/","section":"publication","summary":"Multi-modality model for optic neuropathy diagnose.","tags":["medical imaging"],"title":"Multi-modality fusion learning for the automatic diagnosis of optic neuropathy","type":"publication"},{"authors":["Zheng Cao","Bohan Yu","Biwen Lei","Haochao Ying","Xiao Zhang","Danny Z. Chen","Jian Wu"],"categories":null,"content":" ","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"010d24e3ef82bc1a644e5c1121817dd2","permalink":"www.caoz.top/publication/cascaded-se-resunet-for-segmentation-of-thoracic-organs-at-risk/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"www.caoz.top/publication/cascaded-se-resunet-for-segmentation-of-thoracic-organs-at-risk/","section":"publication","summary":"CT Segmentation of five thoracic organs.","tags":["medical imaging"],"title":"Cascaded SE-ResUnet for segmentation of thoracic organs at risk","type":"publication"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ``` renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() Charts Academic supports the popular Plotly chart format.\nSave your Plotly JSON in your page folder, for example chart.json, and then add the {{\u0026lt; chart data=\u0026quot;chart\u0026quot; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\nYou might also find the Plotly JSON Editor useful.\nMath Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$ renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}{n}) - \\nabla F(\\mathbf{x}{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\\\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ renders as\n$$f(k;p_{0}^{}) = \\begin{cases}p_{0}^{} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ``` renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ``` renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ``` renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ``` renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ``` renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else renders as\nWrite math example Write diagram example Do something else Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell | renders as\nFirst Header Second Header Content Cell Content Cell Content Cell Content Cell Callouts Academic supports a shortcode for callouts, also referred to as asides, hints, or alerts. By wrapping a paragraph in {{% callout note %}} ... {{% /callout %}}, it will render as an aside.\n{{% callout note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /callout %}} renders as\nA Markdown aside is useful for displaying notices, hints, or definitions to your readers. Spoilers Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.\n{{\u0026lt; spoiler text=\u0026quot;Click to view the spoiler\u0026quot; \u0026gt;}} You found me! {{\u0026lt; /spoiler \u0026gt;}} renders as\nClick to view the spoiler You found me!\nIcons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R renders as\nTerminal\nPython\nR\nDid you find this page helpful? Consider sharing it üôå ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"www.caoz.top/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"www.caoz.top/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Zheng Cao"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png') print(\u0026quot;Welcome to Academic!\u0026quot;) Welcome to Academic! Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"www.caoz.top/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"www.caoz.top/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"www.caoz.top/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"www.caoz.top/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"www.caoz.top/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"www.caoz.top/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]